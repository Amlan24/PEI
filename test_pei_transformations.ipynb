{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1fe6026-d7b8-43cf-9d2a-260aa380227a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting pytest\n  Downloading pytest-8.4.0-py3-none-any.whl (363 kB)\nCollecting exceptiongroup>=1\n  Downloading exceptiongroup-1.3.0-py3-none-any.whl (16 kB)\nCollecting iniconfig>=1\n  Downloading iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\nRequirement already satisfied: pygments>=2.7.2 in /databricks/python3/lib/python3.9/site-packages (from pytest) (2.11.2)\nRequirement already satisfied: packaging>=20 in /databricks/python3/lib/python3.9/site-packages (from pytest) (21.3)\nRequirement already satisfied: tomli>=1 in /databricks/python3/lib/python3.9/site-packages (from pytest) (1.2.2)\nCollecting pluggy<2,>=1.5\n  Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\nCollecting typing-extensions>=4.6.0\n  Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /databricks/python3/lib/python3.9/site-packages (from packaging>=20->pytest) (3.0.4)\nInstalling collected packages: typing-extensions, pluggy, iniconfig, exceptiongroup, pytest\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 4.1.1\n    Not uninstalling typing-extensions at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b22b6341-1f4d-4a58-8c13-65464120b8e3\n    Can't uninstall 'typing-extensions'. No files were found to uninstall.\n  Attempting uninstall: pluggy\n    Found existing installation: pluggy 1.0.0\n    Not uninstalling pluggy at /databricks/python3/lib/python3.9/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-b22b6341-1f4d-4a58-8c13-65464120b8e3\n    Can't uninstall 'pluggy'. No files were found to uninstall.\nSuccessfully installed exceptiongroup-1.3.0 iniconfig-2.1.0 pluggy-1.6.0 pytest-8.4.0 typing-extensions-4.14.0\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13de6511-1f19-4f08-8991-315508e729b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import round, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType\n",
    "import pytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0c22651-1a97-4169-b227-69928322a58f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@pytest.fixture(scope=\"module\")\n",
    "def spark():\n",
    "    spark = SparkSession.builder.master(\"local[*]\").appName(\"test\").getOrCreate()\n",
    "    yield spark\n",
    "    spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a2fdffd-9ef5-4432-a6d5-bd9462b42d83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#sample schema\n",
    "orders_schema = StructType([\n",
    "    StructField(\"order_id\", IntegerType()),\n",
    "    StructField(\"customer_id\", IntegerType()),\n",
    "    StructField(\"product_id\", IntegerType()),\n",
    "    StructField(\"profit\", DoubleType())\n",
    "])\n",
    "\n",
    "customers_schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType()),\n",
    "    StructField(\"customer_name\", StringType()),\n",
    "    StructField(\"country\", StringType())\n",
    "])\n",
    "\n",
    "products_schema = StructType([\n",
    "    StructField(\"product_id\", IntegerType()),\n",
    "    StructField(\"category\", StringType()),\n",
    "    StructField(\"sub_category\", StringType())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d58c846e-eeb9-44f7-b2ac-400448bb00c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def test_enriched_table(spark):\n",
    "    #sample data\n",
    "    orders_data = [\n",
    "        (1, 101, 1001, 123.4567),\n",
    "        (2, 102, 1002, 78.9),\n",
    "    ]\n",
    "    customers_data = [\n",
    "        (101, \"Alice\", \"USA\"),\n",
    "        (102, \"Bob\", \"UK\"),\n",
    "    ]\n",
    "    products_data = [\n",
    "        (1001, \"Electronics\", \"Phones\"),\n",
    "        (1002, \"Furniture\", \"Chairs\"),\n",
    "    ]\n",
    "\n",
    "    # sample DataFrame\n",
    "    orders_df = spark.createDataFrame(orders_data, orders_schema)\n",
    "    customers_df = spark.createDataFrame(customers_data, customers_schema)\n",
    "    products_df = spark.createDataFrame(products_data, products_schema)\n",
    "\n",
    "    # orders with customers join\n",
    "    df = orders_df.join(customers_df, \"customer_id\", \"left\")\n",
    "    # Join with products\n",
    "    df = df.join(products_df, \"product_id\", \"left\")\n",
    "    df = df.withColumn(\"profit_rounded\", round(col(\"profit\"), 2))\n",
    "\n",
    "    # result for assertion\n",
    "    result = df.select(\n",
    "        \"order_id\", \"customer_name\", \"country\", \"category\", \"sub_category\", \"profit_rounded\"\n",
    "    ).collect()\n",
    "\n",
    "    expected = [\n",
    "        (1, \"Alice\", \"USA\", \"Electronics\", \"Phones\", 123.46),\n",
    "        (2, \"Bob\", \"UK\", \"Furniture\", \"Chairs\", 78.90)\n",
    "    ]\n",
    "\n",
    "    for row, exp in zip(result, expected):\n",
    "        assert row.order_id == exp[0]\n",
    "        assert row.customer_name == exp[1]\n",
    "        assert row.country == exp[2]\n",
    "        assert row.category == exp[3]\n",
    "        assert row.sub_category == exp[4]\n",
    "        assert abs(row.profit_rounded - exp[5]) < 1e-2\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "test_pei_transformations",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}